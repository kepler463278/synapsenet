# 🚀 SynapseNet v0.8 "Swarm Cognition" - Design Document

## Vision

**v0.7 gave nodes the ability to ACT. v0.8 gives them the ability to THINK TOGETHER.**

Nodes now collaborate to reach consensus on meaning (CoM), reinforce valuable insights (RoV), and iteratively refine understanding through swarm reflection.

**Individual Intelligence (v0.6-v0.7) → Collective Intelligence (v0.8)**

---

## Core Concepts

### 1. CoM (Consensus of Meaning)
Soft consensus on semantic understanding without heavy BFT - weighted aggregation with reflections.

### 2. RoV (Reinforcement of Value)
NGT rewards for valuable contributions - authors of hypotheses and honest validators.

### 3. Swarm Reflection Loop
Iterative refinement: propose → evidence → vote → reflect → converge.

---

## Architecture

```
Goal
    ↓
Swarm Start
    ↓
Round 1: Propose Hypotheses
    ↓
Gather Evidence
    ↓
Collect Votes
    ↓
Aggregate Meaning (CoM)
    ↓
Publish Commit
    ↓
Swarm Reflection
    ↓
Round 2-3: Refine
    ↓
Convergence Check
    ↓
Final MeaningWeight + Rewards (RoV)
```

---

## Data Structures

### Hypothesis
```rust
pub struct Hypothesis {
    pub id: Hash,              // hash(goal_id + content)
    pub goal_id: Uuid,
    pub content: String,       // <= 512 chars
    pub vec: Vec<f32>,         // embedding (384-dim)
    pub author: NodeId,
    pub sig: Signature,
    pub timestamp: i64,
}
```

### Evidence
```rust
pub struct Evidence {
    pub hyp: Hash,
    pub refs: Vec<Hash>,       // grain/episode IDs
    pub confidence: f32,       // 0..1
    pub summary: String,       // 1-2 sentences
    pub sig: Signature,
    pub timestamp: i64,
}
```

### Vote
```rust
pub struct Vote {
    pub hyp: Hash,
    pub support: f32,          // -1..+1
    pub coherence: f32,        // 0..1
    pub novelty: f32,          // 0..1
    pub reuse: f32,            // 0..1
    pub voter: NodeId,
    pub sig: Signature,
    pub timestamp: i64,
}
```

### MeaningWeight
```rust
pub struct MeaningWeight {
    pub hyp: Hash,
    pub weight: f32,           // 0..1+
    pub votes: u32,
    pub round: u32,
    pub committed: bool,
}
```

---

## Algorithms

### Node Weight Calculation
```
node_weight = clip(rep_norm * (1 + reuse_score), 0.1, 3.0)
```

### Hypothesis Weight (Round r)
```
M_r(hyp) = Σ_i node_weight_i * (α*support_i + β*coherence_i + γ*novelty_i + δ*reuse_i)
```

Default weights: α=0.35, β=0.35, γ=0.2, δ=0.1

### Commit Threshold
```
if max(M_r) ≥ τ_commit (0.72) and votes ≥ k_min (7):
    publish_commit()
```

### Hypothesis Merging
```
if cosine(h1.vec, h2.vec) > 0.9:
    merge(h1, h2)
```

### Convergence Check
```
if |M_r - M_{r-1}| < ε (0.02) for top hypotheses:
    converged = true
```

---

## Rewards (RoV)

### Author Reward
```
reward_author = κ * M_commit * (1 + log(1 + evidence_count))
```

### Voter Reward
```
reward_voter_i = λ * node_weight_i * proximity(vote_i, M_commit)
```

### Penalties
- Spam/duplicates → reputation decrease
- Inconsistent evidence → weight reduction
- Sybil attempts → rate limits + stake (v0.9)

---

## P2P Protocol

### GossipSub Topics
- `swarm.propose` - Hypothesis publication
- `swarm.evidence` - Evidence publication
- `swarm.vote` - Vote publication
- `swarm.commit` - MeaningWeight publication

### Anti-Spam
- Rate limiting per node
- Reputation-based filtering
- Duplicate detection via embedding similarity
- Signature verification

---

## Configuration

```toml
[swarm]
alpha = 0.35
beta = 0.35
gamma = 0.2
delta = 0.1
tau_commit = 0.72
k_min = 7
epsilon = 0.02
max_rounds = 3
```

---

## Modules

```
crates/
├─ swarm/
│   ├─ src/schema.rs       // Data structures
│   ├─ src/com.rs          // Consensus of Meaning
│   ├─ src/rov.rs          // Reinforcement of Value
│   ├─ src/loop.rs         // Swarm Reflection Loop
│   └─ tests/*.rs
├─ p2p/
│   ├─ src/swarm_msgs.rs   // P2P messages
│   └─ src/swarm_handlers.rs
├─ api/
│   └─ src/swarm_api.rs    // REST API
└─ storage/
    └─ src/swarm_store.rs  // Local storage
```

---

## REST API

```
POST /swarm/start
{
  "goal_id": "uuid"
}

GET /swarm/status?goal_id=<uuid>
→ Returns current round, hypotheses, weights

GET /swarm/result?goal_id=<uuid>
→ Returns final MeaningWeight + explanation
```

---

## CLI Commands

```bash
# Start swarm consensus
syn swarm start --goal <ID>

# Check status
syn swarm status --goal <ID>

# Get result
syn swarm result --goal <ID> --explain
```

---

## Security

### Signatures
- All messages signed (Ed25519 or Dilithium with --features pqc)
- Signature verification on receipt

### Rate Limiting
- Per-node limits on proposals/votes
- Reputation-based throttling

### Content Policy
- No direct harm instructions
- Risk/consequence discussions allowed

### Sybil Resistance
- Reputation weighting
- Rate limits
- Future: stake requirements (v0.9)

---

## Testing

### Unit Tests
- `merge_similar_hypotheses()`
- `com_commit_happens_when_threshold()`
- `rov_rewards_increase_for_honest_votes()`
- `swarm_reflection_converges_in_rounds()`
- `p2p_roundtrip_messages_ok()`

### Integration Tests
- 10-30 node synthetic scenarios
- Convergence in ≤3 rounds
- Stability with ≥10% malicious nodes
- Reward distribution verification

### Metrics (Prometheus)
- `syn_swarm_hypotheses_total`
- `syn_swarm_votes_total`
- `syn_swarm_commits_total`
- `syn_swarm_round_seconds`
- `syn_swarm_reward_total`

---

## Implementation Phases

### Phase A: Core (4-6 days)
- schema.rs - Data structures
- com.rs - Consensus aggregator
- rov.rs - Reward calculator
- Unit tests

### Phase B: P2P (4-6 days)
- swarm_msgs.rs - Message types
- swarm_handlers.rs - Message handlers
- Deduplication
- Rate limiting
- Reputation integration

### Phase C: API & Storage (3-5 days)
- swarm_store.rs - SQLite storage
- swarm_api.rs - REST endpoints
- CLI commands
- Parquet export

### Phase D: Testing & Metrics (3-4 days)
- Local cluster testing
- Performance profiling
- Documentation (SWARM.md)
- Prometheus metrics

**Total: ~2-3 weeks**

---

## Pseudocode

```rust
fn swarm_consensus(goal: Goal) -> Result<MeaningWeight> {
    let hyps = collect_hypotheses(goal);
    let hyps = merge_similar(hyps);
    
    for round in 1..=cfg.max_rounds {
        let evidences = gather_evidence(hyps);
        let votes = collect_votes(hyps, evidences);
        let mw = aggregate_meaning(hyps, votes);
        
        publish_commit(mw.clone());
        
        if converged(&mw, round) {
            reward(mw.clone(), votes);
            return Ok(best(mw));
        }
        
        reflect_and_counter(hyps, mw);
    }
    
    Ok(best(last_mw))
}
```

---

## Database Schema

```sql
CREATE TABLE hypotheses (
    id TEXT PRIMARY KEY,
    goal_id TEXT NOT NULL,
    content TEXT NOT NULL,
    vec BLOB NOT NULL,
    author TEXT NOT NULL,
    signature TEXT NOT NULL,
    timestamp INTEGER NOT NULL
);

CREATE TABLE evidence (
    id TEXT PRIMARY KEY,
    hyp_id TEXT NOT NULL,
    refs TEXT NOT NULL,
    confidence REAL NOT NULL,
    summary TEXT NOT NULL,
    signature TEXT NOT NULL,
    timestamp INTEGER NOT NULL,
    FOREIGN KEY (hyp_id) REFERENCES hypotheses(id)
);

CREATE TABLE votes (
    id TEXT PRIMARY KEY,
    hyp_id TEXT NOT NULL,
    support REAL NOT NULL,
    coherence REAL NOT NULL,
    novelty REAL NOT NULL,
    reuse REAL NOT NULL,
    voter TEXT NOT NULL,
    signature TEXT NOT NULL,
    timestamp INTEGER NOT NULL,
    FOREIGN KEY (hyp_id) REFERENCES hypotheses(id)
);

CREATE TABLE meaning_weights (
    hyp_id TEXT PRIMARY KEY,
    weight REAL NOT NULL,
    votes INTEGER NOT NULL,
    round INTEGER NOT NULL,
    committed INTEGER NOT NULL,
    timestamp INTEGER NOT NULL,
    FOREIGN KEY (hyp_id) REFERENCES hypotheses(id)
);
```

---

## Success Criteria

- ✅ Convergence in ≤3 rounds (10-30 nodes)
- ✅ Stable with ≥10% malicious nodes
- ✅ Rewards distributed fairly
- ✅ Explainable trace
- ✅ < 5s per round overhead

---

**Status:** Design Complete  
**Next:** Phase A Implementation  
**Version:** 0.8.0-alpha  
**Date:** 2024-11-01

**Nodes now think together as a swarm!** 🧠🐝✨
